\documentclass{article}

\usepackage{a4wide}
\usepackage {amsmath}
\usepackage{amssymb}
\usepackage {graphicx}
\usepackage[utf8]{inputenc} 
\usepackage[francais]{babel}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage{chngpage}
\usepackage{soul}
\usepackage{algorithmicx} 
\usepackage{algpseudocode} 
\usepackage{multicol}
\usepackage[usenames,dvipsnames]{color}
\usepackage{graphicx,float,wrapfig}
\usepackage{ifthen}
\usepackage{listings}
\usepackage{courier}
\usepackage{esint}
\usepackage{bbm}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{epsfig}
\usepackage{pgf,tikz}
\usetikzlibrary{arrows}
\usepackage{braket}
\usepackage{MnSymbol,wasysym}
\usepackage{marvosym}
\usepackage{dsfont}
 \usepackage{stmaryrd}
\usepackage{enumitem}
\usepackage{pst-node}
\usepackage{empheq}

% This is the color used for MATLAB comments below
\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0}

% For faster processing, load Matlab syntax for listings
\lstloadlanguages{Matlab}%
\lstset{language=Matlab,                        % Use MATLAB
        frame=single,                           % Single frame around code
        basicstyle=\small\ttfamily,             % Use small true type font
        keywordstyle=[1]\color{Blue}\bf,        % MATLAB functions bold and blue
        keywordstyle=[2]\color{Purple},         % MATLAB function arguments purple
        keywordstyle=[3]\color{Blue}\underbar,  % User functions underlined and blue
        identifierstyle=,                       % Nothing special about identifiers
                                                % Comments small dark green courier
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small,
        stringstyle=\color{Purple},             % Strings are purple
        showstringspaces=false,                 % Don't put marks in string spaces
        tabsize=5,                              % 5 spaces per tab
        %
        %%% Put standard MATLAB functions not included in the default
        %%% language here
        morekeywords={xlim,ylim,var,alpha,factorial,poissrnd,normpdf,normcdf},
        %
        %%% Put MATLAB function parameters here
        morekeywords=[2]{on, off, interp},
        %
        %%% Put user defined functions here
        morekeywords=[3]{FindESS, homework_example},
        %
        morecomment=[l][\color{Blue}]{...},     % Line continuation (...) like blue comment
        numbers=left,                           % Line numbers on left
        firstnumber=1,                          % Line numbers start with line 1
        numberstyle=\tiny\color{Blue},          % Line numbers are blue
        stepnumber=5                            % Line numbers go in steps of 5
        }

% Includes a MATLAB script.
% The first parameter is the label, which also is the name of the script
%   without the .m.
% The second parameter is the optional caption.
\newcommand{\matlabscript}[2]
  {\begin{itemize}\item[]\lstinputlisting[caption=#2,label=#1]{#1.m}\end{itemize}}
  
\begin{document}

 \title{Projet : méthode itérative des directions alternées (ADI)}

\author{Nathan Toussaint }
\date{\today}
%\date{\vspace{-10ex}}
 
 \maketitle
 
 
\section{Décomposition $LU$ d'une matrice tri-diagonale $T$}

On considère une matrice tridiagonale $T$ de dimension $N \times N$ :
\begin{equation}
T = \begin{pmatrix}
    d_0 & u_0 & 0 & \cdots & 0 \\
    l_1 & d_1 & u_1 & \ddots & \vdots \\
    0 & l_2 & d_2 & \ddots & 0 \\
    \vdots & \ddots & \ddots & \ddots & u_{n-2} \\
    0 & \cdots & 0 & l_{n-1} & d_{n-1}
\end{pmatrix}
\end{equation}
dont les termes diagonaux sont supposés non nuls.

On la stocke en mémoire sous la forme de 3 tableaux de même taille $N$ dont 
les indices commencent à 0 pour faciliter l'implémenation en C.
La diagonale de $T$ est stockée dans le tableau $d$, la première sous-diagonale dans $l$
et la première sur-diagonale dans $u$. On note que les composantes $0$ du vecteur $l$ et la composante $n-1$ du vecteur $u$ ne sont pas pertinentes.

La décomposition LU consiste à écrire la matrice tridiagonale $T$ sous la forme d'un produit $LU$ où

\begin{equation}
L = \begin{pmatrix}
    1 & 0 & 0 & \cdots & 0 \\
    \beta_1 & 1 & 0 & \ddots & \vdots \\
    0 & \beta_2 & 1 & \ddots & 0 \\
    \vdots & \ddots & \ddots & \ddots & 0 \\
    0 & \cdots & 0 & \beta_{n-1} & 1
\end{pmatrix}
\text{\quad et \quad}
U = \begin{pmatrix}
    \alpha_0 & u_0 & 0 & \cdots & 0 \\
    0  & \alpha_1 & u_1 & \ddots & \vdots \\
    0 & 0 &  \ddots & \ddots & 0 \\
    \vdots & \ddots & 0  &\alpha_{n-2} & u_{n-2} \\
    0 & \cdots & 0 & 0 & \alpha_{n-1}
\end{pmatrix}
\end{equation}

Comme la première sur-diagonale supérieure de $U$ s'identifie à celle de la matrice $T$,
 l'algorithme de décomposition LU se simplifie grandement.
 Une première version s'écrit:\\

\begin{algorithmic}[1]
\Function{LU}{$T$}
\State $\alpha_0 \gets d_0$
\For {$k = 1 ..  (n-1)$} 
	\State $\beta_k \gets l_k/\alpha_{k-1}$
	\State $\alpha_k \gets d_k -u_{k-1} \; \beta_k$
\EndFor                 
\EndFunction
\end{algorithmic}

Grâce à la structure tri-diagonale de $T$, il n'est pas nécessaire d'allouer une matrice supplémentaire
pour stocker la décomposition $LU$. Elle peut remplacer progressivement la matrice $T$ ligne par ligne.
L'algorithme optimisé en place mémoire s'écrit finalement : \\

\begin{algorithmic}[1]
\Function{LU}{$T$} \Comment {à la place de la matrice tridiagonale $T$}
\For {$k = 1 ..  (n-1)$} 
	\State $l_k \gets l_k/d_{k-1}$
	\State $d_k \gets d_k -u_{k-1} \; l_k$
\EndFor                 
\EndFunction
\end{algorithmic}

On note que la complexité de la décomposition $LU$ pour une matrice tri-diagonale de rang $N$ est $\vartheta(N)$.
Elle est donc peu couteuse par rapport à celle en $\vartheta(N^3)$ pour une matrice pleine de rang $N$.

\section{Résolution de $T x=b$}

On suppose que la matrice $T$ a été décomposée en un produit $LU$ où $L$ est une matrice bi-diagonale inférieure
avec des $1$ sur la diagonale et $U$ est une matrice bi-diagonale supérieure dont les termes diagonaux sont non nuls.

Résoudre $LU x=b$ s'effectue en deux étapes : i) résolution de $L y=b$ par la méthode de descente pui ii) résolution
de $U x=y$ par la méthode de montée.

\subsection{Résolution de $ L y=b$ par la méthode de descente}

Soit le système d'équations linéaires où la matrice associée est bi-diagonale inférieure:

\begin{equation}
\begin{pmatrix}
    1 & 0 & 0 & \cdots & 0 \\
    l_1 & 1 & 0 & \ddots & \vdots \\
    0 & l_2 & 1 & \ddots & 0 \\
    \vdots & \ddots & \ddots & \ddots & 0 \\
    0 & \cdots & 0 & l_{n-1} & 1
\end{pmatrix}
\begin{pmatrix}
   y_0 \\
   y_1 \\
    \vdots\\
    \vdots \\
    y_{n-1}
\end{pmatrix}
=
\begin{pmatrix}
   b_0 \\
   b_1 \\
    \vdots\\
    \vdots \\
    b_{n-1}
\end{pmatrix}
\end{equation}

La méthode de résolution est celle de la descente. De nouveau, dans le cas de matrice bi-diagonale,
l'algorithme se simplifie et s'écrit:

\begin{algorithmic}[1]
\Function{DESCENTE}{$LU, b$}
\State $y_0 \gets b_0$
\For {$k = 1 ..  (n-1)$} \State $y_k \gets b_k-l_k \; y_{k-1}$
\EndFor                 
\EndFunction
\end{algorithmic}

La complexité de cet algorithme est $\vartheta(N)$.

\subsection{Résolution de $ U x= y$ par la méthode de montée}

Soit le système d'équations linéaires où la matrice associée est bi-diagonale supérieure:
\begin{equation}
U = \begin{pmatrix}
    d_0 & u_0 & 0 & \cdots & 0 \\
    0  & d_1 & u_1 & \ddots & \vdots \\
    0 & 0 &  \ddots & \ddots & 0 \\
    \vdots & \ddots & 0  &d_{n-2} & u_{n-2} \\
    0 & \cdots & 0 & 0 & d_{n-1}
\end{pmatrix}
\begin{pmatrix}
   x_0 \\
   x_1 \\
    \vdots\\
    x_{n-2} \\
    x_{n-1}
\end{pmatrix}
=
\begin{pmatrix}
   y_0 \\
   y_1 \\
    \vdots\\
    y_{n-2} \\
    y_{n-1}
\end{pmatrix}
\end{equation}

L'algorithme de la méthode de la montée s'écrit dans notre cas :
\begin{algorithmic}[1]
\Function{MONTEE}{$LU, y$}
\State $x_{n-1} \gets y_{n-1}/d_{n-1}$
\For {$i = (n-2) .. 1$} \State $x_k \gets (y_k-u_k \; x_{k+1}) / d_k$
\EndFor                 
\EndFunction
\end{algorithmic}

La complexité de cet algorithme est $\vartheta(N)$.

\subsection{Complexité}

La complexité de résolution d'un système tri-diagonale en utilisant la méthode de décomposition $LU$ et les
méthodes de descente et de montée est $\vartheta(N)$ et peu couteuse par rapport à la méthode
de résolution de Gauss qui a une complexité $\vartheta(N^3)$  pour une matrice dense de rang $N$.
   
\section {Méthode de résolution ADI}

 On cherche à résoudre en 2D, l'équation de Poisson  : $-\Delta u(x,y)=f(x,y)$ sur un domaine carré $\Omega=]0, 1[^2$.
 Elle est discrétisée en différences finies sur une grille est de taille $n_x \times n_y$. 
 On impose des conditions de Dirichlet sur le contour $\partial \Omega$ épousant le contour de la grille : $u(x,y)=u^d(x,y)$
 ({\it notation différente du sujet pour réduire les ambiguités de notations avec les indices}).
 
 \subsection{Discrétisation du domaine carré}
 
 On repère chaque noeud de la grille par ses coordonnées entières $(i,j)$ comme dans l'exemple ci-dessous d'une grille
 $5 \times 4$ :
 
 \begin{table}[h]
\begin{center}
\begin{tabular}{ c c c }
\begin{tikzpicture}[scale=1.5]
  \draw (0,0) grid (4,3);
  \foreach \x in {0. ,1. ,...,4.}
    \foreach \y in {0.,1.,...,3.}
      \node at (\x+0.3,\y+0.15) {(\pgfmathparse{int(\x)}\pgfmathresult, \pgfmathparse{int(\y)}\pgfmathresult)};
      
        % Repère cartésien
  \draw[->] (0,0) -- (4.5,0) node[right] {$i$};
  \draw[->] (0, 0) -- (0,3.5) node[above] {$j$};
  
\end{tikzpicture}
\end{tabular}
    \caption{coordonnées entières des noeuds de la grille $5 \times 4$}
    \label{tab:CoordGrille}  
 \end{center}
\end{table}

 Dans l'approximation des différences finies, on définit :
 \begin{equation}
  \left. \hat{ L}_x u \right|_{(i,j)}=\left. -\partial_x^2 u \right|_{(i,j)} = \frac{-u(i-1,j)+2 u(i,j)-u(i+1,j)}{h_x^2}
+ \vartheta(h_x^2)
\end{equation}

 et 
  \begin{equation}
  \left. \hat{L}_y u  \right|_{(i,j)}=\left. -\partial_y^2 u  \right|_{(i,j)}=  \frac{-u(i,j-1)+2 u(i,j)-u(i,j+1)}{h_y^2} + \vartheta(h_y^2)
  \end{equation}
 
 où $h_x=\frac{1}{n_x-1}$ et $h_y=\frac{1}{n_y-1}$ sont les pas de la grille.
 
 Dans la suite, on introduit les notations $m_x =h_x^{-1} = n_x-1$ et $m_y=h_y^{-1}=n_y -1$.

Notons que la fonction $f(x,y)$ est évaluée aux noeuds intérieurs $(i,j)$ de la grille. 

%\begin{table}[h]
%\begin{center}
%\begin{tabular}{ c c c }
%\begin{tikzpicture}
%  \draw (0,0) grid (4,3);
%  \foreach \x in {0. ,1. ,...,4.}
%    \foreach \y in {0.,1.,...,3.}
%      \node at (\x+0.15,\y+0.15) {\pgfmathparse{int(\x+5*(\y))}\pgfmathresult};
%\end{tikzpicture}
%(a)
%&
%\quad \quad
%&
%\begin{tikzpicture}
%  \draw (0,0) grid (4,3);
%  \foreach \x in {0. ,1. ,...,4.}
%    \foreach \y in {0.,1.,...,3.}
%      \node at (\x+0.15,\y+0.15) {\pgfmathparse{int(5*\x+(\y))}\pgfmathresult};
%\end{tikzpicture}
%(b)
%\end{tabular}
%    \caption{Numérotations de la grille $5 \times 4$ en utilisant $n(i,j)=i+j\; n_x$  (a) puis $\bar {n}(i,j)=j+i\; n_y$ (b)}
%    \label{tab:NumGrille}   
% \end{center}
%\end{table}

%\noindent
% L'avantage de la numérotation (a) permet d'écrire de manière la plus compacte :
%   \begin{equation}
% \left. \hat{ L}_x u \right|_{n} = -m_x^2 \; u_{n-1} +2 m_x^2 \; u_n -m_x^2 \; u_{n+1} \text{\quad avec \quad} n(i,j)=i+j\; n_x
%   \end{equation}
%pour tout point intérieur $(i,j)$ de $\Omega$
%tandis que la numérotation (b) étant mieux adaptée pour $L_y$ :
%    \begin{equation}
% \left. \hat{L}_y u \right|_{\bar{n}} = -m_y^2 \; u_{\bar{n}-1} +2 m_y^2 \; u_{\bar{n}} -m_y^2 \; u_{\bar{n}+1}
% \text{\quad avec \quad} \bar{n}(i,j)=j+i\; n_y
%   \end{equation}
%en notant $m_x =h_x^{-1} = n_x-1$ et $m_y=h_y^{-1}=n_y -1$.
 
 \subsection{Les pas fractionnaires de la méthode}
    
La méthode de résolution ADI est une méthode itérative composée de deux pas fractionnaires.
Elle se caractérise par une approche qui alterne entre les directions x et y, en résolvant chaque sous-problème de manière implicite :

 \begin{eqnarray}\left\{ 
\begin{array}{lcl}
  (L_x+\omega_k I) u^* &=& -(L_y-\omega_k I) u^k +b \\
  \\
 (L_y+\omega_k I) u^{k+1} &=& -(L_x-\omega_k I) u^* +b \end{array} \right. 
  \label{ADI}
  \end{eqnarray}
  
Cette alternance permet de transformer la résolution de l'équation bidimensionnelle en deux problèmes unidimensionnels plus simples, qui peuvent être résolus efficacement.
En pratique, la résolution s'arrête lorsque  $||(L_x+L_y) \; u^k -b||_\infty < \epsilon$ avec $\epsilon \approx 10^{-6}$
par exemple, voire plus petit.

 \subsection{Application à la grille $5 \times 4$}
 
On propose de détailler la méthode ADI dans le cas d'une grille de taille $n_x \times n_y = 5 \times 4$. Le premier pas fractionnaire de la méthode ADI consiste à résoudre, pour chacune des lignes $j \in ]0, n_y-1[=\{1, 2\}$. Pour $i \in [1, 3]$, il s'écrit :
\begin{equation}
-m_x^2 u^*_{i-1, j} +(2m_x^2+\omega) u^*_{i, j} -m_x^2 u^*_{i+1, j} =
m_y^2 \; u_{1, j-1}^k - (2m_y^2-\omega)\; u_{1, j}^k +m_y^2 \; u_{1, j+1}^k
+b_{i,j}
\end{equation}
Viennent ensuite s'ajouter les conditions de dirichlet en $i=0$ et $i=n_x-1$.
\noindent
De manière matricielle, le système d'équations à résoudre s'écrit:
\begin{equation}
\begin{pmatrix}
    1 & 0 & 0 & 0 & 0 \\
    -m_x^2 & 2m_x^2+\omega & -m_x^2  & 0 & 0 \\
    0 &  -m_x^2 & 2m_x^2+\omega & -m_x^2  & 0 \\
    0 & 0 &  -m_x^2 & 2m_x^2+\omega & -m_x^2  & \\
    0 & 0 & 0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
   u^*_{0, j}\\
   u^*_{1, j}\\
   u^*_{2, j}\\
   u^*_{3, j}\\
   u^*_{4, j} \\
\end{pmatrix} = \\
\begin{pmatrix}
   0\\
   m_y^2 \; u_{1, j-1}^k - (2m_y^2-\omega)\; u_{1, j}^k +m_y^2 \; u_{1, j+1}^k \\
   m_y^2 \; u_{2, j-1}^k - (2m_y^2-\omega)\; u_{2, j}^k +m_y^2 \; u_{2, j+1}^k \\
   m_y^2 \; u_{3, j-1}^k - (2m_y^2-\omega)\; u_{3, j}^k +m_y^2 \; u_{3, j+1}^k \\
   0 \\
\end{pmatrix}
+
\begin{pmatrix}
   u^d_{0, j}\\
   b_{1, j}\\
   b_{2, j}\\
   b_{3, j}\\
   u^d_{4, j} \\
\end{pmatrix}
\end{equation}
où $u^d_{i,j}$ est la valeur de dirichlet au noeud de coordonnées $(i,j)$.
Cette première étape revient à résoudre $n_y-2$ petits systèmes linéaires dont la matrice est tri-diagonale de rang $n_x$.

De manière similaire, le second pas fractionnaire revient à résoudre, pour chacune des colonnes $i \in ]0, n_x-1[=\{1, 2, 3\}$ :
\begin{equation}
\begin{pmatrix}
    1 & 0 & 0 & 0  \\
    -m_y^2 & 2m_y^2+\omega & -m_y^2  & 0  \\
    0 &  -m_y^2 & 2m_y^2+\omega & -m_y^2  \\
    0 & 0 & 0 &  1
\end{pmatrix}
\begin{pmatrix}
   u^{k+1}_{i, 0}\\
   u^{k+1}_{i, 1}\\
   u^{k+1}_{i, 2}\\
   u^{k+1}_{i, 3}\\
\end{pmatrix} = \\
\begin{pmatrix}
   0\\
   m_x^2 \; u_{i-1, 1}^* - (2m_x^2-\omega)\; u_{i, 1}^* +m_x^2 \; u_{i+1, 1}^* \\
   m_y^2 \; u_{i-1, 2}^* - (2m_x^2-\omega)\; u_{i, 2}^* +m_y^2 \; u_{i+1, 2}^* \\
   0 \\
\end{pmatrix}
+
\begin{pmatrix}
   u^d_{i, 0}\\
   b_{i, 1}\\
   b_{i, 2}\\
   u^d_{i, 4} \\
\end{pmatrix}
\end{equation}

De même, cette seconde étape revient à résoudre $n_x-2$ petits systèmes linéaires dont la matrice est tri-diagonale de rang $n_y$.

Dans l'implémentation, on ne traitera que le cas où les valeurs de $u$ au bord sont strictement nulles.

\begin{table}[h]
\begin{center}
\begin{tabular}{ c c c }
\begin{tikzpicture}[scale=1.5]
  % Grille avec des valeurs entières
  \draw (0,0) grid (3,3);
  \foreach \x in {0,1,...,3}
    \foreach \y in {0,1,...,3}
      \node at (\x+0.15,\y+0.15) {\pgfmathtruncatemacro{\value}{int(\x)+4*int(\y)}\value};

  % Repère cartésien
 %\draw[->] (0,0) -- (4.5,0) node[right] {$i$};
 %\draw[->] (0, 0) -- (0,3.5) node[above] {$j$};
\end{tikzpicture}

\end{tabular}
    \caption{Numérotation unique des noeuds de la grille $4 \times 4$}
    \label{tab:NumGrille}  
 \end{center}
\end{table}

\subsection{Stockage des valeurs aux noeuds sous la forme d'un vecteur}



Du point de vue de l'implémentation, on stockera les approximations de la solution dans un tableau unidimensionnel 
de taille $n_x \times n_y$ en utilisant la relation $n(i,j)=i+j\; n_x$ qui numérote de manière unique chaque noeud $(i,j)$. 


 \subsection{Convergence}
    
On note $\bar u$ la solution de $(L_x+L_y) \bar u =b$. On définit les erreurs $\epsilon^k = u^k-\bar x$ et
$\epsilon^{k+1/2}= u^{k+1/2}-\bar u$.  En soustrayant $(L_x+L_y) \bar u =b$ des équations \eqref{ADI},
on obtient :
 \begin{eqnarray}\left\{ 
\begin{array}{lcl}
  (L_x+\omega_k I) \epsilon^{k+1/2} &=& -(L_y-\omega_k I) \epsilon^k \\
  \\
 (L_y+\omega_k I) \epsilon^{k+1} &=& -(L_x-\omega_k I) \epsilon^{k+1/2}  \end{array}  \right. 
  \label{err}
  \end{eqnarray}
 
Après élimination de $e^{k+1/2}$, on obtient :
\begin{equation}
 \epsilon^{k+1} = (L_y+\omega I)^{-1}  (L_x-\omega I)  (L_x+\omega I)^{-1} (L_y-\omega I) \; \epsilon^k = T(\omega) \epsilon^k
 \label{err}
\end{equation}

Comme les matrices $L_x$ et $L_y$ commutent, on a:
\begin{equation}
T(\omega) = (L_x+\omega I)^{-1} (L_x-\omega I)   (L_y+\omega I)^{-1} (L_y-\omega I)
 \label{Tk}
\end{equation}

A titre d'exemple,  prenons $n_x=n_y=4$, les matrices $L_x$ et $L_y$
en tenant compte des conditions de dirichlet sur les bords sont de la forme et {\bf commutent} entre elles :

\begin{center}
\resizebox{\textwidth}{!}{%
   $L_x=$
   \begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | }
     \hline
     &0. & 1. & 2. & 3. & 4. & 5. & 6. & 7. & 8. & 9. & 10 & 11 & 12 & 13 & 14 & 15 \\ \hline
     0 & 1  &   &   &   &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     1 &  & 1  &   &   &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     2 &  &   &  1 &   &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     3 &  &   &   &  1 &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     4 &  &   &   &   &  1 &   &   &   &  &  &  &  &  &  &  &\\ \hline
     5 &  &   &   &   &  $-m_x^2$ &   $2 m_x^2$&  $-m_x^2$ &   &  &  & & &  &  &  &\\ \hline
     6 &   &  &   &   &   &  $-m_x^2$ &   $2 m_x^2$&  $-m_x^2$ &   &  &  & & &  &  & \\ \hline
     7 &  &   &   &   &   &   &   &  1  &  &  &  &  &  &  &  &\\ \hline
     8 &  &   &   &   &   &   &   &   & 1 &  &  &  &  &  &  &\\ \hline     
     9 & &  & & &  &   &   &   &  $-m_x^2$ &   $2 m_x^2$&  $-m_x^2$ &   &  &  &  &\\ \hline
   10 &  & &  & & &  &   &   &   &  $-m_x^2$ &   $2 m_x^2$&  $-m_x^2$ &   &  &   &\\ \hline
   11 &  &   &   &   &   &   &   &   &  &  &  & 1  &  &  &  &\\ \hline    
   12 &  &   &   &   &   &   &   &   &  &  &  &  & 1  &  &  &\\ \hline    
   13 &  &   &   &   &   &   &   &   &  &  &  &  &  & 1  &  &\\ \hline    
   14 &  &   &   &   &   &   &   &   &  &  &  &  &  &  &  1 &\\ \hline    
   15 &  &   &   &   &   &   &   &   &  &  &  &  &  &  &  & 1\\ \hline    
   \end{tabular}  
   }
 \end{center}

\begin{center}
\resizebox{\textwidth}{!}{%
   $L_y=$
   \begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | }
     \hline
     &0. & 1. & 2. & 3. & 4. & 5. & 6. & 7. & 8. & 9. & 10 & 11 & 12 & 13 & 14 & 15 \\ \hline
     0 & 1  &   &   &   &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     1 &  & 1  &   &   &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     2 &  &   &  1 &   &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     3 &  &   &   &  1 &   &   &   &   &  &  &  &  &  &  &  &\\ \hline
     4 &  &   &   &   &  1 &   &   &   &  &  &  &  &  &  &  &\\ \hline
     5 &  & $-m_y^2$   &   &   &   &   $2 m_y ^2 $&   &   &  &   $-m_y^2$ & & &  &  &  &\\ \hline
     6 &   &  & $-m_y^2$   &   &   &   &   $2 m_y ^2 $&   &   &  &   $-m_y^2$ & & &  &  & \\ \hline
     7 &  &   &   &   &   &   &   &  1  &  &  &  &  &  &  &  &\\ \hline
     8 &  &   &   &   &   &   &   &   & 1 &  &  &  &  &  &  &\\ \hline     
     9 & &  & & &  & $-m_y^2$   &   &   &  &   $2 m_y ^2 $&  &   &  &   $-m_y^2$ &  &\\ \hline
   10 &  & &  & & &  & $-m_y^2$   &   &   &  &   $2 m_y ^2 $&  &   &  &   $-m_y^2$  &\\ \hline
   11 &  &   &   &   &   &   &   &   &  &  &  & 1  &  &  &  &\\ \hline    
   12 &  &   &   &   &   &   &   &   &  &  &  &  & 1  &  &  &\\ \hline    
   13 &  &   &   &   &   &   &   &   &  &  &  &  &  & 1  &  &\\ \hline    
   14 &  &   &   &   &   &   &   &   &  &  &  &  &  &  &  1 &\\ \hline    
   15 &  &   &   &   &   &   &   &   &  &  &  &  &  &  &  & 1\\ \hline    
   \end{tabular}
   }
 \end{center}
 
%Dans la suite, on se limitera au cas $n_x=n_y$, les matrices $L_x$ et $L_y$ ont le même spectre de valeurs
%propres, la vitesse de convergence de l'algorithme itératif est liée à :
%\begin{equation}
%||T_k(\omega_k) || \leq \max_{\lambda_n} \left|  \frac{\lambda_n-\omega_k}{\lambda_n+\omega_k} \right| \times
%\max_{\lambda_n} \left|  \frac{\lambda_n-\omega_k}{\lambda_n+\omega_k} \right|
%\end{equation}

Les valeurs propres de $T(\omega)$ valent $\frac{\lambda_n-\omega}{\lambda_n+\omega}  
\frac{\gamma_n-\omega}{\gamma_n+\omega}$ et son rayon spectral vaut $
\max_{\lambda_n, \gamma_n} \left| \frac{\lambda_n-\omega}{\lambda_n+\omega}  \times
\frac{\gamma_n-\omega}{\gamma_n+\omega} \right|$.
Pour $\omega>0$, la fonction $\varphi(\lambda) = \frac{\lambda-\omega}{\lambda+\omega}$
est croissante

\end{document}
